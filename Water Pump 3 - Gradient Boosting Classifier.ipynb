{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "train = r\"C:\\Users\\me\\Documents\\datasets\\pump_train_for_models.csv\"\n",
    "test = r\"C:\\Users\\me\\Documents\\datasets\\pump_test_for_models.csv\"\n",
    "\n",
    "train = pd.read_csv(train)\n",
    "test = pd.read_csv(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get dummy columns for the categorical columns and shuffle the data.\n",
    "\n",
    "dummy_cols = ['funder', 'installer', 'basin', 'public_meeting', 'scheme_management', 'permit',\n",
    "              'construction_year', 'extraction_type_class', 'payment_type', 'water_quality',\n",
    "              'quantity', 'source_type', 'source_class', 'waterpoint_type',\n",
    "             'waterpoint_type_group']\n",
    "\n",
    "train = pd.get_dummies(train, columns = dummy_cols)\n",
    "\n",
    "train = train.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.get_dummies(test, columns = dummy_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's split the train set into train and validation sets. Also remove the target.\n",
    "\n",
    "target = train.status_group\n",
    "features = train.drop('status_group', axis=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(features, target, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Both the train and test set are ready for modelling. I'll use a gradient boosting algorithm.\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
    "\n",
    "def model(X_train, X_val, y_train, y_val, test):\n",
    "    if __name__ == '__main__':\n",
    "    \n",
    "        param_grid = {'learning_rate': [0.075, 0.7],\n",
    "                      'max_depth': [13, 14],\n",
    "                      'min_samples_leaf': [15, 16],\n",
    "                      'max_features': [1.0],\n",
    "                      'n_estimators': [100, 200]}                      \n",
    "\n",
    "        estimator = GridSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                                 param_grid=param_grid,\n",
    "                                 n_jobs=-1)\n",
    "\n",
    "        estimator.fit(X_train, y_train)\n",
    "\n",
    "        best_params = estimator.best_params_\n",
    "\n",
    "        print (best_params)\n",
    "                                 \n",
    "        validation_accuracy = estimator.score(X_val, y_val)\n",
    "        print('Validation accuracy: ', validation_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_leaf': 16, 'n_estimators': 100, 'learning_rate': 0.075, 'max_features': 1.0, 'max_depth': 14}\n",
      "Validation accuracy:  0.796043771044\n"
     ]
    }
   ],
   "source": [
    "model(X_train, X_val, y_train, y_val, test)\n",
    "#{'min_samples_leaf': 16, 'n_estimators': 100, 'learning_rate': 0.075, 'max_features': 1.0, 'max_depth': 14}\n",
    "#Validation accuracy:  0.796043771044"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get data necessary for submission.\n",
    "\n",
    "submit_loc = r\"C:\\Users\\me\\Documents\\datasets\\pump_submit.csv\"\n",
    "test_id = pd.read_csv(submit_loc)\n",
    "test_id.columns = ['idd', 'status_group']\n",
    "test_id = test_id.idd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def model_for_submission(features, target, test):\n",
    "    if __name__ == '__main__':\n",
    "\n",
    "         best_params = {'learning_rate': [0.075],\n",
    "                        'max_depth': [14],\n",
    "                        'min_samples_leaf': [16],\n",
    "                        'max_features': [1.0],\n",
    "                        'n_estimators': [100]}                      \n",
    "\n",
    "         estimator = GridSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                                 param_grid=best_params,\n",
    "                                 n_jobs=-1)\n",
    "\n",
    "         estimator.fit(features, target)     \n",
    "\n",
    "         predictions = estimator.predict(test)\n",
    "\n",
    "         data = {'ID': test_id, 'status_group': predictions}\n",
    "\n",
    "         submit = pd.DataFrame(data=data)\n",
    "\n",
    "         vals_to_replace = {2:'functional', 1:'functional needs repair',\n",
    "                           0:'non functional'}\n",
    "\n",
    "         submit.status_group = submit.status_group.replace(vals_to_replace)        \n",
    "\n",
    "         submit.to_csv('pump_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run model for submission.\n",
    "\n",
    "model_for_submission(features, target, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The model scored 0.8073. Which leaves me ranking 203/2147 (as of 04/10/2016) which is just \n",
    "# inside the top ten percent. \n",
    "# Below are scores from other models I ran using less variables.\n",
    "# The modifications helped to improve the model. \n",
    "\n",
    "#Score: 0.7809 without funder.\n",
    "#Score: 0.7826 with funder.\n",
    "#Score: 0.7859 with funder and installer.\n",
    "#Score: 0.7875 with funder, installer and scheme management.\n",
    "#Score: 0.7923 with funder, installer, scheme management and extractor type.\n",
    "#Score: 0.7949 with funder, installer, scheme management, extractor type and basin\n",
    "#Score: 0.7970 with funder, installer, scheme management, extractor type, basin and a \n",
    "#              unmodified version of water quality."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
